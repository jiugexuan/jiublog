---
title: 【《深度学习》】线性代数
date: 2022-03-31 07:00:00 +/-0800
categories: [书籍笔记,《深 度 学 习》]
tags: [《深 度 学 习》]     # TAG names should always be lowercase 标记名称应始终为小写
---

## 标量、向量、矩阵和张量

线性代数主要研究的是以下几种对象：

- <b>标量(scalar)</b>：标量就是单一的数字，比如单一的整数，实数，有理数等都是标量。

- <b>向量(vector)</b>：可以看做是一组标量形成的一维数组，如由n个实数组成的向量：

<div align=center><img width = '100' height ='150' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E5%90%91%E9%87%8F.png"/></div>



- <b>矩阵(matrix)</b>: 矩阵是二维数组，所以每个元素需要行和列的指标来标记

<div align=center><img width = '200' height ='110' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84.png"/></div>

- <b>张量(tensor)</b>：张量是多维数组，当它是零维时就是标量，一维时就是矢量，二维时就是矩阵，也可以大于二维。


## 矩阵运算

- <b>转置(transpose)</b>:矩阵转置可以想成将矩阵按轴线翻转过来，矩阵A的转置常常用 <font face="Times New Roman"><b><i>A<sup>T</sup></i></b></font> 表示

<div align=center><img src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/AT%E8%BD%AC%E7%BD%AE.png"/></div>


- <b>矩阵乘法(matrix product)</b>:假如有两个形状分别为 m x n 的矩阵A和 n x p 的矩阵B，注意A的列数和B的行数要匹配，矩阵乘积C=AB就是将A的每一行与对应的B的每一列相乘求和，并将所得的数存储在C的对应元素中：

<div align=center><img width = '214' height ='80' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95.png"/></div>

  矩阵与向量的乘积可以看做是矩阵与矩阵乘积的一种特殊情况。我们常用的n元一次线性方程组也可以表示为矩阵与向量的乘积形式

  <div align=center><img width = '' height ='50' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84.png"/></div>


## 单位矩阵和逆矩阵

- <b>逆矩阵(inverse matrix)</b>:首先我们需要定义单位矩阵(Identity Matrix) <font face="Times New Roman"><b><i>I<sub>n</sub></i></b></font> , <font face="Times New Roman"><b><i>I<sub>n</sub></i></b></font> 是一个<font face="Times New Roman"><b><i>n &times; n</i></b></font>的方形矩阵，并且主对角线均为1，其他元素均为零，单位矩阵与任意向量相乘还得到该向量本身。矩阵A的逆矩阵常用 <font face="Times New Roman"><b><i>A<sup>-1</sup></i></b></font> 表示，其性质是

  <div align=center><img width = '' height ='50' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E9%80%86%E7%9F%A9%E9%98%B5.png"/></div>

假如一个矩阵存在逆矩阵，那么相应的线性方程组就可以转化为求逆矩阵与向量的矩阵乘积的问题：
  <div align=center><img width = '' height ='200' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E9%80%86%E7%9F%A9%E9%98%B5%E6%B1%82%E8%A7%A3.png"/></div>

## 线性相关和生成子空间
如果逆矩阵 <font face="Times New Roman"><b><i>A<sup>-1</sup></i></b></font> 存在，那么  <font face="Times New Roman"><b><i>A x = b</i></b></font>  肯定对于每一个向量 <font face="Times New Roman"><b><i>b</i></b></font> 恰好存在一个解。但是，对于方程组而言，对于向量 <font face="Times New Roman"><b><i>b</i></b></font> 的某些值，有可能不存在解，或者存在无限多个解。

为了分析方程有多少个解，我们可以将 <font face="Times New Roman"><b><i>A</i></b></font> 的列向量看作是从 <b>原点（origin）</b>（元
素都是零的向量）出发的不同方向，确定有多少种方法可以到达向量 <font face="Times New Roman"><b><i>b</i></b></font> 。在这个观点
下，向量 <font face="Times New Roman"><b><i>x</i></b></font> 中的每个元素表示我们应该沿着这些方向走多远，即 <font face="Times New Roman"><b><i>x<sub>i</sub></i></b></font>  表示我们需要沿
着第  <font face="Times New Roman"><b><i>i</i></b></font>  个向量的方向走多远：

  <div align=center><img width = '' height ='70' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E8%B5%B0%E6%96%B9%E5%90%91.png"/></div>

  一般而言，这种操作被称为<b>线性组合（linear combination）</b>。形式上，一组向量的线性组合，是指每个向量乘以对应标量系数之后的和，即：

  <div align=center><img width = '' height ='70' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E7%BA%BF%E6%80%A7%E7%BB%84%E5%90%88.png"/></div>

  - <b>生成子空间（span）</b>：原始向量线性组合后所能抵达的点的集合。

确定 <font face="Times New Roman"><b><i>A x = b</i></b></font> 是否有解相当于确定向量 <font face="Times New Roman"><b><i>b</i></b></font> 是否在 <font face="Times New Roman"><b><i>A</i></b></font> 列向量的生成子空间中。这个特殊的生成子空间被称为 <font face="Times New Roman"><b><i>A</i></b></font> 的<b>列空间（column space）</b>或者 <font face="Times New Roman"><b><i>A</i></b></font> 的<b>值域（range）</b>。

为了使方程 <font face="Times New Roman"><b><i>A x = b</i></b></font> 对于任意向量 <font face="Times New Roman"><b><i>b &#8712; &Ropf;<sup>m</sup></i></b></font> 都存在解，我们要求 <font face="Times New Roman"><b><i>A</i></b></font> 的列空间构成整个<font face="Times New Roman"><b><i> &Ropf;<sup>m</sup></i></b></font>。如果<font face="Times New Roman"><b><i> &Ropf;<sup>m</sup></i></b></font> 中的某个点不在 <font face="Times New Roman"><b><i>A</i></b></font> 的列空间中，那么该点对应的 <font face="Times New Roman"><b><i>b</i></b></font> 会使得该方程没有解。矩阵 <font face="Times New Roman"><b><i>A</i></b></font> 的列空间是整个 <font face="Times New Roman"><b><i> &Ropf;<sup>m</sup></i></b></font> 的要求，意味着 <font face="Times New Roman"><b><i>A</i></b></font> 至少有<font face="Times New Roman"><b><i>m</i></b></font> 列，即 <font face="Times New Roman"><b><i>n &ge; m</i></b></font>。否则，<font face="Times New Roman"><b><i>A</i></b></font> 列空间的维数会小于 <font face="Times New Roman"><b><i>m</i></b></font> 。例如，假设 <font face="Times New Roman"><b><i>A</i></b></font> 是一个<font face="Times New Roman"><b><i>3 &times; 2</i></b></font> 的矩阵。目标 <font face="Times New Roman"><b><i>b</i></b></font> 是 3 维的，但是 <font face="Times New Roman"><b><i>x</i></b></font> 只有 2 维。所以无论如何修改<font face="Times New Roman"><b><i>x</i></b></font> 的值，也只能描绘出 <font face="Times New Roman"><b> &Ropf;<sup>3</sup></b></font> 空间中的二维平面。当且仅当向量 <font face="Times New Roman"><b><i>b</i></b></font> 在该二维平面中时，该方程有解。

> 不等式 <font face="Times New Roman"><b><i>n &ge; m</i></b></font> 仅是方程对每一点都有解的必要条件。这不是一个充分条件，因为有些列向量可能是冗余的。假设有一个<font face="Times New Roman"><b> &Ropf;<sup>2 &times; 2</sup></b></font> 中的矩阵，它的两个列向量是相同的。那么它的列空间和它的一个列向量作为矩阵的列空间是一样的。换言之，虽然该矩阵有 2 列，但是它的列空间仍然只是一条线，不能涵盖整个<font face="Times New Roman"><b> &Ropf;<sup>2 </sup></b></font> 空间。

正式地说，这种冗余被称为 <b>线性相关（linear dependence）</b>。如果一组向量中的任意一个向量都不能表示成其他向量的线性组合，那么这组向量被称为 <b>线性无关（linearly independent）</b>。如果某个向量是一组向量中某些向量的线性组合，那么我们将这个向量加入到这组向量后不会增加这组向量的生成子空间。这意味着，如果一个矩阵的列空间涵盖整个<font face="Times New Roman"><b> &Ropf;<sup>m</sup></b></font>，那么该矩阵必须包含至少一组 <font face="Times New Roman"><b><i>m</i></b></font> 个线性无关的向量。这是式 <font face="Times New Roman"><b><i>A x = b</i></b></font> 对于每一个向量 <font face="Times New Roman"><b><i>b</i></b></font> 的取值都有解的充分必要条件。值得注意的是， 这个条件是说该向量集恰好有 <font face="Times New Roman"><b><i>m</i></b></font>个线性无关的列向量，而不是至少 <font face="Times New Roman"><b><i>m</i></b></font> 个。不存在一个 <font face="Times New Roman"><b><i>m</i></b></font> 维向量的集合具有多于 <font face="Times New Roman"><b><i>m</i></b></font> 个彼此线性不相关的列向量，但是一个有多于 <font face="Times New Roman"><b><i>m</i></b></font> 个列向量的矩阵却有可能拥有不止一个大小为 <font face="Times New Roman"><b><i>m</i></b></font> 的线性无关向量集。

要想使矩阵可逆，我们还需要保证式 <font face="Times New Roman"><b><i>A x = b</i></b></font> 对于每一个 <font face="Times New Roman"><b><i>b</i></b></font> 值至多有一个解。为此，我们需要确保该矩阵至多有 <font face="Times New Roman"><b><i>m</i></b></font> 个列向量。否则，该方程会有不止一个解。

综上所述，这意味着该矩阵必须是一个 <b>方阵（square）</b>，即 <font face="Times New Roman"><b><i> m = n </i></b></font> ，并且所有列向量都是线性无关的。一个列向量线性相关的方阵被称为 <b>奇异的（singular）</b>。

如果矩阵 <font face="Times New Roman"><b><i> A </i></b></font> 不是一个方阵或者是一个奇异的方阵，该方程仍然可能有解。但是我们不能使用矩阵逆去求解。目前为止，我们已经讨论了逆矩阵左乘。我们也可以定义逆矩阵右乘：

<div align=center><img width = '' height ='50' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E7%9F%A9%E9%98%B5%E5%8F%B3%E4%B9%98.png"/></div>

>对于方阵而言，它的左逆和右逆是相等的。

## 范数

- <b>范数(norm)</b>:范数用来度量向量的大小。比如 <font face="Times New Roman"><i><b> L<sup> p </sup></b></i></font> 一般定义为

<div align=center><img width = '' height ='70' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E8%8C%83%E6%95%B0.png"/></div>

其中<font face="Times New Roman"><b><i> p &#8712; &Ropf;，p &ge; 1 </i></b></font>。

范数（包括<font face="Times New Roman"><i><b> L<sup> p</sup></b></i></font> 范数）是将向量映射到非负值的函数。直观上来说，向量 <font face="Times New Roman"><b><i> x </i></b></font> 的
范数衡量从原点到点 <font face="Times New Roman"><b><i> x </i></b></font> 的距离。更严格地说，范数是满足下列性质的任意函数：

<div align=center><img width = '' height ='' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E8%8C%83%E6%95%B0%E7%89%B9%E5%BE%81.png"/></div>


当<font face="Times New Roman"><i><b> p = 2</b></i></font> 时，<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数被称为 <b>欧几里得范数（Euclidean norm）</b>。它表示从原点
出发到向量 <font face="Times New Roman"><b><i> x </i></b></font> 确定的点的欧几里得距离。<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数在机器学习中出现地十分频繁，经常简化表示为<font face="Times New Roman"><b>  ∥x∥</b></font>，略去了下标 2。平方<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数也经常用来衡量向量的大小，可以简单地通过点积<font face="Times New Roman"><i><b>  x<sup> T </sup>x</b></i></font> 计算。

平方<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数在数学和计算上都比<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数本身更方便。例如，平方<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数对<font face="Times New Roman"><b><i> x </i></b></font> 中每个元素的导数只取决于对应的元素，而<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数对每个元素的导数却和整个向量相关。但是在很多情况下，平方<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数也可能不受欢迎，因为它在原点附近增长得十分缓慢。在某些机器学习应用中，区分恰好是零的元素和非零但值很小的元素是很重要的。在这些情况下，我们转而使用在各个位置斜率相同，同时保持简单的数学形式的函数：<font face="Times New Roman"><i><b>  L<sup> 1</sup></b></i></font> 范数。<font face="Times New Roman"><i><b>  L<sup> 1</sup></b></i></font> 范数可以简化如下：

<div align=center><img width = '' height ='70' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/L.png"/></div>


> 当机器学习问题中零和非零元素之间的差异非常重要时，通常会使用<font face="Times New Roman"><i><b> L<sup> 1</sup></b></i></font> 范数。每当 <font face="Times New Roman"><b><i> x </i></b></font> 中某个元素从0 增加 &epsilon;，对应的<font face="Times New Roman"><i><b>  L<sup> 1</sup></b></i></font> 范数也会增加 &epsilon;。


有时候我们会统计向量中非零元素的个数来衡量向量的大小。有些作者将这种
函数称为 "<font face="Times New Roman"><i><b>  L<sup> 0</sup></b></i></font> 范数"，但是这个术语在数学意义上是不对的。向量的非零元素的数目不是范数，因为对向量缩放 	&alpha; 倍不会改变该向量非零元素的数目。因此，<font face="Times New Roman"><i><b>  L<sup> 1</sup></b></i></font> 范数经常作为表示非零元素数目的替代函数。

另外一个经常在机器学习中出现的范数是<font face="Times New Roman"><i><b>  L<sup> &infin;</sup></b></i></font>  范数，也被称为<b>最大范数（max norm）</b>。这个范数表示向量中具有最大幅值的元素的绝对值：


<div align=center><img width = '' height ='70' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/L%20inifinit.png"/></div>


有时候我们可能也希望衡量矩阵的大小。在深度学习中，最常见的做法是使用<b>Frobenius 范数（Frobenius norm）</b>，


<div align=center><img width = '' height ='80' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/frobenius.png"/></div>


其类似于向量的<font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数。

两个向量的<b>点积（dot product）</b>可以用范数来表示。具体地，
<div align=center><img width = '' height ='70' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E7%82%B9%E7%A7%AF.png"/></div>

其中 <font face="Times New Roman"><b><i> &theta; </i></b></font>表示 <font face="Times New Roman"><b><i> x </i></b></font> 和 <font face="Times New Roman"><b><i> y </i></b></font> 之间的夹角。

## 特殊类型的矩阵和向量

- <b>对角矩阵</b>（diagonal matrix）：只在主对角线上含有非零元素，其他位置都是零。对角矩阵受到关注的部分原因是对角矩阵的乘法计算很高效。

- <b>对称矩阵(symmetric matrix)</b>：对称矩阵的转置等于它自身。

<div align=center> <font face="Times New Roman"><b><i> A = A <sup>T</sup> </i></b></font></div>

- <b>对角矩阵(diagonal matrix)</b>：除主对角线的元素均为零。

- <b>单位向量(unit vector)</b>: 单位向量的 <font face="Times New Roman"><i><b>  L<sup> 2</sup></b></i></font> 范数等于 1 。

如果<font face="Times New Roman"><b><i>  x <sup>T</sup>y = 0  </i></b></font>，那么向量 <font face="Times New Roman"><b><i> x </i></b></font> 和向量 <font face="Times New Roman"><b><i> y </i></b></font> 互相 <b>正交 （orthogonal）</b>。如果两个向量都有非零范数，那么这两个向量之间的夹角是 90 度。在<font face="Times New Roman"><b> &Ropf;<sup>n </sup></b></font> 中，至多有 <font face="Times New Roman"><b><i> n </i></b></font> 个范数非
零向量互相正交。如果这些向量不仅互相正交，并且范数都为 1，那么我们称它们
是 <b>标准正交（orthonormal）</b>。

- <b>正交矩阵(orthogonal matrix)</b>: 正交矩阵的转置与它自身的矩阵乘积是单位矩阵：

<div align=center> <font face="Times New Roman"><b><i>  A <sup>T</sup>A =AA <sup>T</sup> = I  </i></b></font></div>

>我们需要注意正交矩阵的定义。反直觉地，正交矩阵的行向量不仅是正交的，还是标准正交的。对于行向量或列向量互相正交但不是标准正交的矩阵没有对应的专有术语。

## 特征分解

正如我们可以把正整数表示为更基本的质数的乘积的形式，<b>特征分解(eigendecomposition)</b >也是将矩阵分解为组成它的 <b>特征向量(eigenvector)</b> 和 <b>特征值(eigenvalue)</b> 的形式。

特征向量定义如下：如果正方形矩阵 <font face="Times New Roman"><b><i> A </i></b></font> 和向量 <font face="Times New Roman"><b><i> v </i></b></font> 的乘积可以表示为一个标量 <font face="Times New Roman"><b><i> &lambda; </i></b></font> 与向量<font face="Times New Roman"><b><i> v </i></b></font>的乘积，那么 <font face="Times New Roman"><b><i> v </i></b></font> 就是 <font face="Times New Roman"><b><i> A </i></b></font> 的一个特征向量，  <font face="Times New Roman"><b><i> &lambda; </i></b></font> 就是<font face="Times New Roman"><b><i> A </i></b></font> 的一个特征值：

<div align=center> <font face="Times New Roman"><b><i>  A v = &lambda; v  </i></b></font></div>

可以看出，如果 <font face="Times New Roman"><b><i> v </i></b></font> 就是 <font face="Times New Roman"><b><i> A </i></b></font> 的一个特征向量，那么任意一个标量与 <font face="Times New Roman"><b><i> v </i></b></font> 的乘积仍是 <font face="Times New Roman"><b><i> A </i></b></font> 的一个特征向量，而且他们的特征值相同，所以通常我们只关心范数为1的特征向量。假设我们将矩阵A的所有特征向量连成一个矩阵 <font face="Times New Roman"><b><i> v </i></b></font> ： <font face="Times New Roman"><b> V = [ <i>v<sup> (1)</sup> , … , v<sup> (n)</sup></i>] </b></font>  ，而对应的特征值连成一个向量 <font face="Times New Roman"><b> &lambda; = [ <i>&lambda;<sub> 1 </sub> , … , &lambda;<sub> n </sub></i>]<sup> T</sup> </b></font> ，那么矩阵 <font face="Times New Roman"><b><i> A </i></b></font> 就可以表示为它的特征分解形式：

<div align=center> <font face="Times New Roman"><b><i>  A = V diag( &lambda; ) v  <sup> -1</sup></i></b></font></div>

<br/>

<div align=center><img width = '' height ='' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3.png"/></div>

特征向量和特征值的作用效果。特征向量和特征值的作用效果的一个实例。在这里，矩阵<font face="Times New Roman"><b><i> A </i></b></font> 有两个标准正交的特征向量，对应特征值为 <font face="Times New Roman"><b><i> &lambda;<sub>1</sub></i></b></font> 的<font face="Times New Roman"><b><i> v <sup>(1)</sup></i></b></font> 以及对应特征值为  <font face="Times New Roman"><b><i> &lambda;<sub>2</sub></i></b></font> 的<font face="Times New Roman"><b><i> v <sup>(2)</sup></i></b></font>。(左) 我们画出了所有的单位向量 <font face="Times New Roman"><b>u &#8712; &Ropf;<sup>2</sup></b></font>的集合，构成一个单位圆。(右) 我们画出了所有的 <font face="Times New Roman"><b><i> Au </i></b></font> 点的集
合。通过观察 <font face="Times New Roman"><b><i> A </i></b></font>  拉伸单位圆的方式，我们可以看到它将 <font face="Times New Roman"><b><i> v <sup>(i)</sup></i></b></font>  方向的空间拉伸了<font face="Times New Roman"><b><i> &lambda;<sub>i</sub></i></b></font> 倍。


>当然，不是所有矩阵都可以做特征分解，比较幸运的是，通常我们可能要解决的只是某类特定形式的矩阵问题，例如实对称矩阵总可以表示成特征分解的形式。

矩阵的特征分解给了我们很多关于矩阵的有用信息。矩阵是奇异的当且仅当含
有零特征值。实对称矩阵的特征分解也可以用于优化二次方程   <font face="Times New Roman"><b><i>  f(x) = x<sup>T</sup>Ax </i></b></font>，其中限制 <font face="Times New Roman"><b>||x||<sub>2</sub> = 1</b></font> 当 <font face="Times New Roman"><b><i> x </i></b></font>  等于<font face="Times New Roman"><b><i> A </i></b></font>  的某个特征向量时，<font face="Times New Roman"><b><i> f </i></b></font>  将返回对应的特征值。在限制条件下，函数 <font face="Times New Roman"><b><i> f </i></b></font>  的最大值是最大特征值，最小值是最小特征值。

所有特征值都是正数的矩阵被称为 <b>正定（positive definite）</b>；所有特征值都是非负数的矩阵被称为 <b>半正定（positive semidefinite）</b>。同样地，所有特征值都是负数的矩阵被称为 <b>负定（negative definite）</b>；所有特征值都是非正数的矩阵被称为 <b>半负定（negative semidefinite）</b>。半正定矩阵受到关注是因为它们保证 <font face="Times New Roman"><i><b>&forall; x; x<sup>⊤</sup>Ax &ge; 0</b></i></font>。此外，
正定矩阵还保证 <font face="Times New Roman"><i><b>x<sup>⊤</sup>Ax =  0 &rArr;  x=0 </b></i></font>。

## 奇异值分解

<b>SVD</b> 全称是 <b> Single Value Decomposition奇异值分解</b>。和特征分解类似，它也是将矩阵分解为更基本的组合乘积，而且SVD更具有普适性，对于矩阵本身的要求很少，基本上所有实数矩阵都可以做SVD分解，而特征分解对于非对称矩阵是无能为力的。

SVD将矩阵表示为三个矩阵的乘积形式：

<div align=center> <font face="Times New Roman"><b><i>  A  = UDV <sup>T</sup> </i></b></font></div>

其中 <font face="Times New Roman"><b><i> A </i></b></font>是<font face="Times New Roman"><b><i> m &times; n </i></b></font>的矩阵，<font face="Times New Roman"><b><i> U </i></b></font>是<font face="Times New Roman"><b><i> m &times; m </i></b></font>的矩阵，<font face="Times New Roman"><b><i> D </i></b></font>是<font face="Times New Roman"><b><i> m &times; n </i></b></font>的矩阵, <font face="Times New Roman"><b><i> V </i></b></font>是<font face="Times New Roman"><b><i> n &times; n </i></b></font>的矩阵 <font face="Times New Roman"><b><i> U </i></b></font> 和 <font face="Times New Roman"><b><i> V </i></b></font>均是正交矩阵，而 <font face="Times New Roman"><b><i> D </i></b></font> 是对角矩阵。

>注意，矩阵 <font face="Times New Roman"><b><i> D </i></b></font> 不一定是方阵。

对角矩阵 <font face="Times New Roman"><b><i> D </i></b></font>对角线上的元素被称为矩阵 <font face="Times New Roman"><b><i> A </i></b></font> 的 <b>奇异值（singular value）</b>。矩阵<font face="Times New Roman"><b><i> U </i></b></font>的列向量被称为 <b>左奇异向量（left singular vector）</b>，矩阵 <font face="Times New Roman"><b><i> V </i></b></font> 的列向量被称 <b>右奇异向量（right singular vector）</b>。


事实上，我们可以用与 <font face="Times New Roman"><b><i> A </i></b></font> 相关的特征分解去解释 <font face="Times New Roman"><b><i> A </i></b></font> 的奇异值分解。<font face="Times New Roman"><b><i> A </i></b></font> 的左奇异向量（left singular vector）是 <font face="Times New Roman"><b><i>  AA <sup>T</sup>  </i></b></font> 的特征向量。<font face="Times New Roman"><b><i> A </i></b></font> 的右奇异向量（right singularvector）是 <font face="Times New Roman"><b><i>  A <sup>T</sup>A   </i></b></font> 的特征向量。<font face="Times New Roman"><b><i> A </i></b></font> 的非零奇异值是<font face="Times New Roman"><b><i>  A <sup>T</sup>A   </i></b></font> 特征值的平方根，同时也是<font face="Times New Roman"><b><i>  AA <sup>T</sup>  </i></b></font> 特征值的平方根

SVD在很多方面有重要的作用，比如在推荐系统里，我们有矩阵 <font face="Times New Roman"><b><i> A </i></b></font>来表示用户对影片的评分，那么SVD可以看做是将其映射到某个隐性特征（例如影片风格）的过程，其中<font face="Times New Roman"><b><i>  U   </i></b></font>即为(用户,隐性特征）矩阵，<font face="Times New Roman"><b><i>  V   </i></b></font>即为（影片，隐性特征）矩阵，而 <font face="Times New Roman"><b><i> D  </i></b></font>就代表了每个隐性特征的重要性，我们如果想压缩存储空间的话可以只选择<font face="Times New Roman"><b><i>  D   </i></b></font>的一些较大的对角元素，而相应的选取出U和V的对应行列形成新矩阵，通过压缩后的 <font face="Times New Roman"><b><i>  U',D',V'  </i></b></font> 再重构的矩阵 <font face="Times New Roman"><b><i>  A'  </i></b></font>可以较好的还原矩阵<font face="Times New Roman"><b><i> A </i></b></font>而没有较大的失真。

## Moore-Penrose 伪逆

对于非方矩阵而言，其逆矩阵没有定义。假设在下面的问题中，我们希望通过
矩阵 <font face="Times New Roman"><b><i>  A  </i></b></font> 的左逆<font face="Times New Roman"><b><i>  B  </i></b></font> 来求解线性方程，

<div align=center> <font face="Times New Roman"><b><i>  Ax = y </i></b></font></div>

等式两边左乘左逆 <font face="Times New Roman"><b><i> B </i></b></font> 后，我们得到

<div align=center> <font face="Times New Roman"><b><i> x = By </i></b></font></div>

<br/>

取决于问题的形式，我们可能无法设计一个唯一的映射将 <font face="Times New Roman"><b><i> A </i></b></font> 映射到 <font face="Times New Roman"><b><i> B </i></b></font>。

如果矩阵 <font face="Times New Roman"><b><i> A </i></b></font>的行数大于列数，那么上述方程可能没有解。如果矩阵 <font face="Times New Roman"><b><i> A </i></b></font> 的行数小于列数，那么上述矩阵可能有多个解。

<b>Moore-Penrose 伪逆（Moore-Penrose pseudoinverse）</b>使我们在这类问题上
取得了一定的进展矩阵 <font face="Times New Roman"><b><i> A </i></b></font> 的伪逆定义为：

<div align=center><img width = '' height ='80' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E4%BC%AA%E9%80%86.png"/></div>

计算伪逆的实际算法没有基于这个定义，而是使用下面的公式：


<div align=center> <font face="Times New Roman"><b><i>  A <sup>+</sup> = UD<sup>+</sup>V <sup>T</sup> </i></b></font></div>

其中，矩阵 <font face="Times New Roman"><b><i> U </i></b></font>，<font face="Times New Roman"><b><i>D </i></b></font> 和<font face="Times New Roman"><b><i> V </i></b></font> 是矩阵<font face="Times New Roman"><b><i>  A  </i></b></font>奇异值分解后得到的矩阵。对角矩阵<font face="Times New Roman"><b><i>D </i></b></font>的伪逆 <font face="Times New Roman"><b><i>D <sup>+</sup></i></b></font> 是其非零元素取倒数之后再转置得到的。

当矩阵<font face="Times New Roman"><b><i>  A  </i></b></font> 的列数多于行数时，使用伪逆求解线性方程是众多可能解法中的一种。特别地，<font face="Times New Roman"><b><i>  x = A <sup>+</sup> y  </i></b></font> 是方程所有可行解中欧几里得范数 <font face="Times New Roman"><b>||<i>x</i>||<sub>2</sub></b></font>最小的一个。

当矩阵<font face="Times New Roman"><b><i>  A  </i></b></font>的行数多于列数时，可能没有解。在这种情况下，通过伪逆得到的x使得<font face="Times New Roman"><b><i>  Ax  </i></b></font> 和<font face="Times New Roman"><b><i>  y  </i></b></font> 的欧几里得距离 <font face="Times New Roman"><b>||<i>Ax - y</i>||<sub>2</sub></b></font> 最小 

## 迹运算

迹运算返回的是矩阵对角元素的和：

<div align=center><img width = '' height ='80' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/%E8%BF%B92.png"/></div>

迹运算因为很多原因而有用。若不使用求和符号，有些矩阵运算很难描述，而通过矩阵乘法和迹运算符号，可以清楚地表示。例如，迹运算提供了另一种描述矩阵Frobenius 范数的方式

<div align=center><img width = '' height ='80' src="https://raw.githubusercontent.com/jiugexuan/image-repository/main/fo.png"/></div>


## 行列式

行列式，记作 <font face="Times New Roman"><b><i>det(A)</i></b></font>，是一个将方阵 <font face="Times New Roman"><b><i>A</i></b></font> 映射到实数的函数。行列式的值等于矩阵特征值的乘积。行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或者缩小了多少。如果行列式是 0，那么空间至少沿着某一维完全收缩了，使其失去了所有的体积。如果行列式是 1，那么这个转换保持空间体积不变。

## 实例：主成分分析